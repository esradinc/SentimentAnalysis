# -*- coding: utf-8 -*-
"""DuyguAnalizi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15QPrW_s_-BJry9xgdGCew59rWgHDKQFG
"""

import pandas as pd
import matplotlib.pyplot as plt
import string
import nltk
from nltk.corpus import stopwords
import logging
logging.getLogger("nltk").setLevel(logging.CRITICAL)  # NLTK'nin loglarını baskılar
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn import svm
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
import warnings
warnings.filterwarnings("ignore")
from sklearn.ensemble import VotingClassifier

"""**Veri setini okuyalım örnek verileri görelim**"""

#df_orijinal = pd.read_csv('/magaza_yorumlari.csv', encoding='utf-16')
df_orijinal = pd.read_csv('/yeni_magaza_yorumlari.csv', encoding='utf-16')
print("\n\nDataset {:d} satır ve {:d} sütundan oluşmaktadır.".format(len(df_orijinal), len(df_orijinal.columns)))
print("\n\nÖrnek Veriler: \n",df_orijinal.head())

"""Veri Setinin bir kopyasını oluşturalım ve gerekli işlemleri kopya üzerinden yapalım."""

df_copy=df_orijinal.copy()

"""**VERİ ANALİZİ VE VERİ TEMİZLEME**

Yorumların durum dağılımlarını inceleyeceğiz.
"""

df_copy['Durum'] = df_copy['Durum'].apply(lambda x: x if x in ['Olumlu', 'Olumsuz'] else 'Diğer')

yorum_sayilari = df_copy['Durum'].value_counts()

olumlu_yorumlar = yorum_sayilari.get('Olumlu', 0)
olumsuz_yorumlar = yorum_sayilari.get('Olumsuz', 0)
diger_yorumlar = yorum_sayilari.get('Diğer', 0)
print("\nYorumların Dağılımı:")
print(f"Olumlu Yorumlar: {olumlu_yorumlar}")
print(f"Olumsuz Yorumlar: {olumsuz_yorumlar}")
print(f"Diğer Yorumlar: {diger_yorumlar}")

categories = yorum_sayilari.index
frequencies = yorum_sayilari.values

plt.figure(figsize=(8, 6))
plt.bar(categories, frequencies, color=['blue', 'red', 'green'])
plt.xlabel('Durum')
plt.ylabel('Yorum Sayısı')
plt.title('Yorum Dağılımı: Olumlu, Olumsuz ve Diğer')
plt.show()

"""Null değer var mı kontrol edelim"""

gorus_null_sayisi = df_copy['Görüş'].isnull().sum()

durum_null_sayisi = df_copy['Durum'].isnull().sum()

print(f"Görüş kısmı null olan veri sayısı: {gorus_null_sayisi}")
print(f"Durum kısmı null olan veri sayısı: {durum_null_sayisi}")

"""Null değer içeren satırları Veri setinden silelim"""

df_copy = df_copy.dropna(subset=['Görüş', 'Durum'])
print("\n\nDataset {:d} satırdan oluşmaktadır".format(len(df_copy)))

"""Durum Sütunundaki değerlerin tüm harflerini küçük harfe dönüştürelim."""

df_copy['Durum'] = df_copy['Durum'].str.lower()
print(df_copy.head())

"""olumlu, olumsuz etiketleri dışında kalan verileri silelim."""

df_copy = df_copy[df_copy['Durum'] != 'diğer']
print("\n\nDataset {:d} satırdan oluşmaktadır.".format(len(df_copy)))
yorum_sayilari = df_copy['Durum'].value_counts()
olumlu_yorumlar = yorum_sayilari.get('olumlu', 0)
olumsuz_yorumlar = yorum_sayilari.get('olumsuz', 0)
diger_yorumlar = yorum_sayilari.get('diğer', 0)
print("\nYorumların Dağılımı:")
print(f"Olumlu Yorumlar: {olumlu_yorumlar}")
print(f"Olumsuz Yorumlar: {olumsuz_yorumlar}")
print(f"Diğer Yorumlar: {diger_yorumlar}")

"""Veri setinde tekrar eden veriler var mı inceleyelim."""

tekrarlayanlar = df_copy[df_copy.duplicated(subset=['Görüş', 'Durum'], keep=False)].copy()
tekrarlayanlar['tekrar_sayisi'] = tekrarlayanlar.groupby(['Görüş', 'Durum'])['Görüş'].transform('count')

tekrarlayanlar_benzersiz = tekrarlayanlar.drop_duplicates(subset=['Görüş', 'Durum'])
tekrarlayanlar_benzersiz = tekrarlayanlar_benzersiz.reset_index(drop=True)

if len(tekrarlayanlar_benzersiz)!=0 :
    print("Tekrar eden kayıtlar:")
    print(tekrarlayanlar_benzersiz)
else :
    print('Tekrar eden kayıt yok.')

toplam_tekrar = tekrarlayanlar_benzersiz['tekrar_sayisi'].sum()
print("\nTekrar eden kayıtların toplam sayısı:", toplam_tekrar)

fazlalik_sayisi = toplam_tekrar - len(tekrarlayanlar_benzersiz)
print("Fazlalıkların sayısı:", fazlalik_sayisi)

"""Tekrar eden verileri verisetinden silelim"""

fazlalik_sayisi = tekrarlayanlar_benzersiz['tekrar_sayisi'].sum() - len(tekrarlayanlar_benzersiz)
df_copy = df_copy.drop_duplicates(subset=['Görüş', 'Durum'], keep='first').reset_index(drop=True)

print("Fazlalıkların sayısı:", fazlalik_sayisi)
print("Kalan toplam kayıt sayısı:", len(df_copy))

"""Olumlu ve olumsuz etiketleri 1 ve 0 olarak sayısal değere dönüştürelim."""

df_copy['Görüş'] = df_copy['Görüş'].str.lower()
df_copy['Durum'] = df_copy['Durum'].apply(lambda x: 1 if x == 'olumlu' else (0 if x == 'olumsuz' else x))

print(df_copy.head())

"""Gereksiz Karakterler ve Noktalama işaretlerini silelim."""

df_copy['Görüş'] = df_copy['Görüş'].str.translate(str.maketrans('', '', string.punctuation))
print(df_copy.head())

"""Stopword leri temizleyelim. NLTK kütüphanesinde bulunan stopwordlerle kendi oluşturduğumuz stopwordlistesini bir arada kullanarak temizleme işlemi yapalım"""

nltk.download('stopwords', quiet=True)  # quiet=True ile log bastırılmaz
nltk_stop_words = set(stopwords.words('turkish'))

with open('/TurkishStopwords.txt', 'r', encoding='utf-8') as file:
    stop_words = set(file.read().splitlines())

combined_stop_words = nltk_stop_words.union(stop_words)

def remove_stopwords(text):
    if pd.isnull(text):
        return text
    words = text.split()
    filtered_words = [word for word in words if word not in combined_stop_words]
    return ' '.join(filtered_words)

df_copy['Görüş'] = df_copy['Görüş'].apply(remove_stopwords)

print(df_copy[['Görüş']].head())

"""**TF-IDF**, metin verilerini sayısal verilere dönüştürmek için kullanılan bir vektörizasyon yöntemidir. Bir kelimenin, bir belgede ne kadar sık geçtiğini (TF) ve o kelimenin tüm belgeler arasında ne kadar nadir olduğunu (IDF) dikkate alır.

Sık geçen ancak her belgede bulunan kelimelerin önemini azaltırken, belirli belgelerde anlamlı olan kelimelerin ağırlığını artırır. TF-IDF, özellikle metin sınıflandırma ve bilgi arama gibi uygulamalarda, metinlerden anlam çıkarma ve önemli kelimeleri belirleme amacıyla yaygın olarak kullanılır.

Temizlediğimiz verisetini test ve train olarak ikiye ayıralım ve metinleri vektörize edelim.
"""

vectorizer = TfidfVectorizer(max_features =  5000)
X = df_copy['Görüş']
y = df_copy['Durum']

X_vectorized = vectorizer.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)

"""İlk olarak **Lojistik Regresyon** modelinu kullanarak eğitim yapacağız.

Lojistik regresyon, bağımlı değişkenin kategorik olduğu durumlarda kullanılan bir tahmin yöntemidir. İkili sınıflandırma problemlerinde (örneğin, evet/hayır), verileri sigmoid fonksiyonu ile modelleyerek bir olayın gerçekleşme olasılığını hesaplar.
Lojistik regresyon, lineer regresyon ile benzer bir şekilde çalışır, ancak sonuçları sigmoid fonksiyonu ile sınırlandırarak 0 ile 1 arasında olasılık değerleri üretir.


**Sigmoid fonksiyonu**, lojistik regresyonda kullanılan, bir sayıyı 0 ile 1 arasında bir değere dönüştüren matematiksel bir fonksiyondur. Bu fonksiyon, bir sınıflandırma probleminde, örneğin bir olayın olma olasılığını tahmin etmek için kullanılır.

GridSearchCV kullanarak oluşturacağımız modeller için kullanacağımız en iyi parametreleri seçerek modelleri eğiteceğiz.

**GridSearchCV**, makine öğrenimi modellerinin hiperparametre optimizasyonu için kullanılan bir yöntemdir.

GridSearchCV, belirttiğiniz hiperparametre kombinasyonlarını sistematik olarak dener ve en iyi performansı sağlayan parametreleri otomatik olarak seçer.

Lojistik Regresyon modeli için en uygun parametre seçimini yapalım.

**Regularization parametresi** : overfitting önlemek için seçilecek parametredir.

**Solver**: Lojistik regresyon problemini çözmek için kullanılan optimizasyon algoritmasıdır.
* **liblinear**: Küçük veri setleri için uygundur.
* **lbfgs**: Daha büyük veri setleri için önerilir.
"""

# Parametre grid'ini tanımlayalım
param_grid_logreg = {
    'C': [0.01, 0.1, 1, 10, 100],  # Regularization parametresi
    'solver': ['liblinear', 'lbfgs']  # Çözümleyiciler
}
# GridSearchCV tanımlama
grid_search_logreg = GridSearchCV(
    estimator=LogisticRegression(max_iter=5000),
    param_grid=param_grid_logreg,
    scoring='accuracy',  # Doğruluk skoruna göre optimize etmek için
    cv=5,
    verbose=1,
    n_jobs=-1  # Paralel işlem için tüm işlemciler kullanılsın
)

# Modeli eğitme
grid_search_logreg.fit(X_train, y_train)

# En iyi parametreleri alalım
best_params_logreg = grid_search_logreg.best_params_
print(f"En İyi Parametreler (Lojistik Regresyon): {best_params_logreg}")

"""Bulunan en iyi parametreler ile Lojistik regresyon modelini eğitelim ve doğruluk oranını inceleyelim."""

# Lojistik regresyon modelini oluşturalım
modellogreg = LogisticRegression(C=1, solver='lbfgs', max_iter=5000)
modellogreg.fit(X_train, y_train)

# Test setinde tahmin yapma
y_pred = modellogreg.predict(X_test)

# Accuracy hesaplayalım
accuracy = (y_pred == y_test).mean()

print(f"Lojistik Regresyon Modeli Doğruluk Değeri (Accuracy): {accuracy:.4f}")

"""**Naive Bayes**, Bayes teoremine dayalı, basit ama etkili bir sınıflandırma algoritmasıdır. Özellikle özelliklerin birbirinden bağımsız olduğu varsayımıyla çalışır. Bu algoritma, her bir sınıf için olasılık hesaplamaları yaparak, en yüksek olasılığa sahip sınıfı tahmin eder. Genellikle metin sınıflandırma, spam e-posta filtresi ve duygu analizi gibi uygulamalarda kullanılır.

**Naive Bayes** yöntemi için en uygun parametreyi belirleyelim.
"""

# Parametre grid'i yalım
param_grid_nb = {'alpha': [0.1, 0.5, 1, 2, 5]}  #Model genellemesini iyileştirmek için kullanılacak değer

# GridSearchCV tanımlama
grid_search_nb = GridSearchCV(
    estimator=MultinomialNB(),
    param_grid=param_grid_nb,
    scoring='accuracy',
    cv=5,
    verbose=1,
    n_jobs=-1
)

# Modeli eğit
grid_search_nb.fit(X_train, y_train)

# En iyi parametreleri al
best_params_nb = grid_search_nb.best_params_
print(f"En İyi Parametreler (Naive Bayes): {best_params_nb}")

"""Naive Bayes modelini bulunan paramete ile eğiterek sonucu değerlendirelim"""

model_nb = MultinomialNB(alpha=0.5)

# Modeli eğitim verisiyle eğitelim
model_nb.fit(X_train, y_train)

# Test setinde tahmin yapalım
y_pred_nb = model_nb.predict(X_test)

accuracy_nb = (y_pred_nb == y_test).mean()

print(f"\nNaive Bayes Modeli Doğruluk Değeri (Accuracy): {accuracy_nb:.4f}")

"""**Destek Vektör Makinesi(SVM)**, veriyi ayıran en uygun sınırı (hiper düzlem) bulmaya çalışır ve bu sayede sınıflar arasındaki farkı mümkün olan en geniş mesafeyle belirler. Bu özellik, SVM'yi genelleme konusunda oldukça başarılı kılar. Ayrıca, doğrusal olmayan verilerle çalışırken 'kernel' fonksiyonları kullanarak veriyi daha yüksek boyutlu bir uzaya dönüştürür, böylece karmaşık sınırlar oluşturabilir. SVM, metin sınıflandırma, yüz tanıma ve daha pek çok alanda yaygın bir şekilde kullanılır."""

'''
param_grid = {
    'C': [0.1, 1, 10, 100],  # Düzenleme parametresi
    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Çekirdek fonksiyonları
    'gamma': ['scale', 'auto'],
    'probability': [True]  # Probability True olarak ayarlanmalı
}

# GridSearchCV nesnesini oluştur
grid_search = GridSearchCV(
    estimator=SVC(),
    param_grid=param_grid,
    scoring='accuracy',  # Doğruluğa göre en iyi parametreleri bul
    cv=5,  # 10 katlı çapraz doğrulama
    verbose=1,
    n_jobs=-1  # Paralel işlem için tüm işlemcileri kullan
)

grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
print(f"En İyi Parametreler: {best_params}")

'''

"""En iyi modeli bulduktan sonra model eğitimini yapalım.

**Not**: Bu aşama uzun sürdüğü için parametreleri bulduktan sonra kodu bir daha çalıştırmak istemediğim için kapattım.
"""

svm_model = SVC(C=1, gamma='scale', kernel='rbf', probability=True)

svm_model.fit(X_train, y_train)

y_pred_svm = svm_model.predict(X_test)

svm_accuracy = (y_pred_svm == y_test).mean()

print(f"\nSVM Modeli Doğruluk Değeri (Accuracy): {svm_accuracy:.4f}")

"""**ÖZET**

Lojistik Regresyon: 0.9045

Naive Bayes: 0.8969

SVM: 0.9075

**Voting Classifier**, birden fazla sınıflandırma modelini bir araya getiren bir yöntemdir. Farklı modeller her bir veri için tahminde bulunur ve VotingClassifier bu tahminlerin çoğunluk veya ortalama oyu ile son kararı verir. Yani, bir modelin zayıf olduğu durumlarda diğer modellerin güçlü tarafları devreye girer. Bu sayede, tek bir modelin sınıflandırmadaki hatalarını azaltarak daha sağlam ve doğru sonuçlar elde edilebilir. Özellikle farklı algoritmaların birleşimi, modelin genel başarısını artırır.

Voting Classifier'da kullanılan iki farklı oy verme yöntemi vardır.
**Hard voting**, sınıflandırıcıların en fazla oy verdiği sınıfı seçerken,** soft voting** her sınıfın olasılığını dikkate alarak karar verir.

Kullandığımız modellerden daha iyi sonuç almak için Voting Classifier yöntemi ile eğitim yapalım.
"""

# VotingClassifier oluşturalım
voting_clf = VotingClassifier(estimators=[
    ('logreg', modellogreg),
    ('svm', svm_model),
    ('nb', model_nb)
], voting='hard')


# Modeli eğit
voting_clf.fit(X_train, y_train)

y_pred_voting = voting_clf.predict(X_test)

voting_accuracy = (y_pred_voting == y_test).mean()

print(f"\nVoting Modeli Doğruluk Değeri (Accuracy): {voting_accuracy:.4f}")

voting_clf = VotingClassifier(estimators=[
    ('logreg', modellogreg),
    ('svm', svm_model),
    ('nb', model_nb),],
     voting='soft')

voting_clf.fit(X_train, y_train)

y_pred_voting = voting_clf.predict(X_test)

voting_accuracy = (y_pred_voting == y_test).mean()

print(f"\nSoft Voting Modeli Doğruluk Değeri (Accuracy): {voting_accuracy:.4f}")

"""Sonuç olarak Lojistik Regresyon ile 0.9045, Naive Bayes ile 0.8969 ve SVM ile  0.9075 olarak elde ettiğimiz doğruluk değerlerini **Hard voting yöntemi ile 0.9087** ve **Soft voting yöntemi ile 0.9128** olarak elde edip doğruluk değerini arttırmış olduk."""

yeni_yorum = ["Bu ürün gerçekten çok kötü."]

# Yorumu vektörize edelim
yeni_yorum_vectorized = vectorizer.transform(yeni_yorum)

# Tahmin yapalım
tahmin = voting_clf.predict(yeni_yorum_vectorized)

if tahmin[0] == 1:
    print("Tahmin edilen sınıf: olumlu")
else:
    print("Tahmin edilen sınıf: olumsuz")